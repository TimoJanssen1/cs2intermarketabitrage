{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS2 Inter-Market Arbitrage Analysis\n",
        "\n",
        "This notebook performs exploratory data analysis, identifies arbitrage opportunities, and evaluates risk metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import sqlite3\n",
        "\n",
        "from src.db.client import DatabaseClient\n",
        "from src.analysis.risk import RiskAnalyzer\n",
        "\n",
        "# Set pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data from Database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize database client\n",
        "db_client = DatabaseClient('db/arbitrage.sqlite')\n",
        "\n",
        "# Get latest snapshots\n",
        "snapshots = db_client.get_latest_snapshots()\n",
        "\n",
        "print(f\"Loaded {len(snapshots)} item snapshots\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_snapshots = pd.DataFrame(snapshots)\n",
        "df_snapshots.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Calculate PnL and Derived Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize risk analyzer\n",
        "risk_analyzer = RiskAnalyzer(tc_steam=0.15)\n",
        "\n",
        "# Filter out items with missing data\n",
        "df_clean = df_snapshots[\n",
        "    df_snapshots['steam_best_bid'].notna() & \n",
        "    df_snapshots['buff_best_ask'].notna()\n",
        "].copy()\n",
        "\n",
        "# Calculate metrics\n",
        "df_clean['adj_steam_bid'] = df_clean['steam_best_bid'] * (1 - 0.15)\n",
        "df_clean['pnl_now'] = df_clean['adj_steam_bid'] - df_clean['buff_best_ask']\n",
        "df_clean['spread_pct'] = (df_clean['pnl_now'] / df_clean['buff_best_ask']) * 100\n",
        "\n",
        "# Filter positive PnL\n",
        "df_positive = df_clean[df_clean['pnl_now'] > 0].copy()\n",
        "\n",
        "print(f\"Items with positive PnL: {len(df_positive)} / {len(df_clean)}\")\n",
        "print(f\"\\nTop 10 by PnL:\")\n",
        "df_positive.nlargest(10, 'pnl_now')[['market_hash_name', 'steam_best_bid', 'buff_best_ask', 'pnl_now', 'spread_pct']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.5. Spread Distribution Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot spread distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram of spreads\n",
        "axes[0].hist(df_clean['spread_pct'], bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0].axvline(x=0, color='r', linestyle='--', label='Break-even')\n",
        "axes[0].set_xlabel('Spread %')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Distribution of Spreads (All Items)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Box plot: positive vs negative spreads\n",
        "df_clean['spread_category'] = df_clean['spread_pct'].apply(lambda x: 'Positive' if x > 0 else 'Negative')\n",
        "df_clean.boxplot(column='spread_pct', by='spread_category', ax=axes[1])\n",
        "axes[1].set_xlabel('Spread Category')\n",
        "axes[1].set_ylabel('Spread %')\n",
        "axes[1].set_title('Spread Distribution by Category')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary stats\n",
        "print(f\"Mean spread: {df_clean['spread_pct'].mean():.2f}%\")\n",
        "print(f\"Median spread: {df_clean['spread_pct'].median():.2f}%\")\n",
        "print(f\"Std dev: {df_clean['spread_pct'].std():.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Price History and Volatility Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get price history for top candidates\n",
        "top_items = df_positive.nlargest(5, 'pnl_now')\n",
        "\n",
        "volatility_data = []\n",
        "\n",
        "for _, row in top_items.iterrows():\n",
        "    item_id = row['item_id']\n",
        "    price_history = db_client.get_price_history(item_id, days=7)\n",
        "    \n",
        "    steam_prices = [\n",
        "        float(s.get('best_bid', 0) or s.get('median_price', 0))\n",
        "        for s in price_history.get('steam', [])\n",
        "        if s.get('best_bid') or s.get('median_price')\n",
        "    ]\n",
        "    \n",
        "    if len(steam_prices) >= 2:\n",
        "        volatility = risk_analyzer.calculate_volatility(steam_prices)\n",
        "        volatility_data.append({\n",
        "            'item_id': item_id,\n",
        "            'market_hash_name': row['market_hash_name'],\n",
        "            'volatility': volatility,\n",
        "            'price_observations': len(steam_prices),\n",
        "            'current_pnl': row['pnl_now']\n",
        "        })\n",
        "\n",
        "df_volatility = pd.DataFrame(volatility_data)\n",
        "print(\"Volatility Analysis:\")\n",
        "df_volatility\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5. Price History Time Series\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot price history for top candidates\n",
        "if len(df_positive) > 0:\n",
        "    top_item = df_positive.nlargest(1, 'pnl_now').iloc[0]\n",
        "    item_id = top_item['item_id']\n",
        "    item_name = top_item['market_hash_name']\n",
        "    \n",
        "    price_history = db_client.get_price_history(item_id, days=7)\n",
        "    \n",
        "    # Prepare data\n",
        "    steam_data = price_history.get('steam', [])\n",
        "    buff_data = price_history.get('buff', [])\n",
        "    \n",
        "    if steam_data and buff_data:\n",
        "        # Convert to DataFrames\n",
        "        steam_df = pd.DataFrame(steam_data)\n",
        "        buff_df = pd.DataFrame(buff_data)\n",
        "        \n",
        "        # Parse timestamps\n",
        "        steam_df['timestamp'] = pd.to_datetime(steam_df['timestamp'])\n",
        "        buff_df['timestamp'] = pd.to_datetime(buff_df['timestamp'])\n",
        "        \n",
        "        # Get prices\n",
        "        steam_df['price'] = steam_df['best_bid'].fillna(steam_df.get('median_price', 0))\n",
        "        buff_df['price'] = buff_df['best_ask']\n",
        "        \n",
        "        # Plot\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(steam_df['timestamp'], steam_df['price'], marker='o', label='Steam (bid)', alpha=0.7)\n",
        "        plt.plot(buff_df['timestamp'], buff_df['price'], marker='s', label='Buff (ask)', alpha=0.7)\n",
        "        \n",
        "        # Add adjusted Steam line (after fee)\n",
        "        if 'price' in steam_df.columns:\n",
        "            steam_df['adj_price'] = steam_df['price'] * 0.85\n",
        "            plt.plot(steam_df['timestamp'], steam_df['adj_price'], \n",
        "                    marker='x', label='Steam (adj for 15% fee)', linestyle='--', alpha=0.7)\n",
        "        \n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Price')\n",
        "        plt.title(f'Price History: {item_name[:50]}')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Insufficient price history for {item_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Risk Analysis with Monte Carlo Simulation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.5. Risk Metrics Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Risk metrics plots\n",
        "if len(df_risk) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Probability of positive PnL distribution\n",
        "    axes[0, 0].hist(df_risk['prob_positive'], bins=30, edgecolor='black', alpha=0.7)\n",
        "    axes[0, 0].axvline(x=0.5, color='r', linestyle='--', label='50% threshold')\n",
        "    axes[0, 0].set_xlabel('Probability of Positive PnL')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].set_title('Distribution of P(Positive PnL)')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Expected PnL vs Current PnL\n",
        "    axes[0, 1].scatter(df_risk['pnl_now'], df_risk['expected_pnl'], alpha=0.6)\n",
        "    axes[0, 1].plot([df_risk['pnl_now'].min(), df_risk['pnl_now'].max()], \n",
        "                    [df_risk['pnl_now'].min(), df_risk['pnl_now'].max()], \n",
        "                    'r--', label='y=x (no change)')\n",
        "    axes[0, 1].set_xlabel('Current PnL')\n",
        "    axes[0, 1].set_ylabel('Expected PnL after hold')\n",
        "    axes[0, 1].set_title('Current vs Expected PnL')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. VaR distribution\n",
        "    axes[1, 0].hist(df_risk['var_95'], bins=30, edgecolor='black', alpha=0.7)\n",
        "    axes[1, 0].axvline(x=0, color='r', linestyle='--', label='Break-even')\n",
        "    axes[1, 0].set_xlabel('95% VaR (loss)')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    axes[1, 0].set_title('Distribution of 95% Value at Risk')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Risk-return scatter\n",
        "    axes[1, 1].scatter(df_risk['var_95'], df_risk['expected_pnl'], \n",
        "                       c=df_risk['prob_positive'], cmap='RdYlGn', alpha=0.6, s=50)\n",
        "    axes[1, 1].set_xlabel('95% VaR (risk)')\n",
        "    axes[1, 1].set_ylabel('Expected PnL (return)')\n",
        "    axes[1, 1].set_title('Risk-Return Profile (color = P(positive))')\n",
        "    cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
        "    cbar.set_label('P(Positive PnL)')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze hold period risk for top candidates\n",
        "hold_days = 3\n",
        "risk_results = []\n",
        "\n",
        "for _, row in df_positive.nlargest(10, 'pnl_now').iterrows():\n",
        "    steam_bid = float(row['steam_best_bid'])\n",
        "    buff_ask = float(row['buff_best_ask'])\n",
        "    \n",
        "    # Get volatility\n",
        "    item_id = row['item_id']\n",
        "    price_history = db_client.get_price_history(item_id, days=7)\n",
        "    steam_prices = [\n",
        "        float(s.get('best_bid', 0) or s.get('median_price', 0))\n",
        "        for s in price_history.get('steam', [])\n",
        "        if s.get('best_bid') or s.get('median_price')\n",
        "    ]\n",
        "    \n",
        "    if len(steam_prices) < 2:\n",
        "        volatility = 0.10  # Default 10%\n",
        "    else:\n",
        "        volatility = risk_analyzer.calculate_volatility(steam_prices)\n",
        "    \n",
        "    # Risk analysis\n",
        "    risk_metrics = risk_analyzer.analyze_hold_period_risk(\n",
        "        steam_bid, buff_ask, volatility, hold_days\n",
        "    )\n",
        "    \n",
        "    risk_results.append({\n",
        "        'item_id': item_id,\n",
        "        'market_hash_name': row['market_hash_name'],\n",
        "        'pnl_now': row['pnl_now'],\n",
        "        'volatility': volatility,\n",
        "        **risk_metrics\n",
        "    })\n",
        "\n",
        "df_risk = pd.DataFrame(risk_results)\n",
        "print(\"Risk Analysis Results:\")\n",
        "df_risk[['market_hash_name', 'pnl_now', 'volatility', 'prob_positive', 'expected_pnl', 'var_95']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualizations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.5. Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix for key metrics\n",
        "if len(df_risk) > 0:\n",
        "    # Combine data\n",
        "    df_corr = df_risk[['pnl_now', 'spread_pct', 'volatility', 'prob_positive', \n",
        "                       'expected_pnl', 'var_95']].copy()\n",
        "    \n",
        "    # Calculate correlation\n",
        "    corr_matrix = df_corr.corr()\n",
        "    \n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    im = plt.imshow(corr_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
        "    plt.colorbar(im, label='Correlation')\n",
        "    \n",
        "    # Add text annotations\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(len(corr_matrix.columns)):\n",
        "            text = plt.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}',\n",
        "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
        "    \n",
        "    plt.xticks(range(len(corr_matrix.columns)), corr_matrix.columns, rotation=45, ha='right')\n",
        "    plt.yticks(range(len(corr_matrix.columns)), corr_matrix.columns)\n",
        "    plt.title('Correlation Matrix: Key Metrics')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nKey Correlations:\")\n",
        "    print(f\"Spread vs Expected PnL: {df_corr['spread_pct'].corr(df_corr['expected_pnl']):.3f}\")\n",
        "    print(f\"Volatility vs VaR: {df_corr['volatility'].corr(df_corr['var_95']):.3f}\")\n",
        "    print(f\"Expected PnL vs P(Positive): {df_corr['expected_pnl'].corr(df_corr['prob_positive']):.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogram of PnL\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_positive['pnl_now'], bins=30, edgecolor='black')\n",
        "plt.xlabel('PnL (currency units)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Current PnL')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.5. Ask-Only Pressure: Additional Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additional analysis for ask-only pressure theory\n",
        "if len(df_imbalance) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # 1. Ask/Bid ratio distribution\n",
        "    axes[0, 0].hist(df_imbalance['imbalance_ratio'], bins=50, edgecolor='black', alpha=0.7)\n",
        "    axes[0, 0].axvline(x=1, color='r', linestyle='--', label='Balanced (1:1)')\n",
        "    axes[0, 0].set_xlabel('Ask/Bid Ratio')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "    axes[0, 0].set_title('Distribution of Ask/Bid Ratios')\n",
        "    axes[0, 0].set_xlim(0, min(10, df_imbalance['imbalance_ratio'].quantile(0.95)))\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Ask count vs Bid count scatter\n",
        "    axes[0, 1].scatter(df_imbalance['bid_count'], df_imbalance['ask_count'], alpha=0.6)\n",
        "    max_val = max(df_imbalance['ask_count'].max(), df_imbalance['bid_count'].max())\n",
        "    axes[0, 1].plot([0, max_val], [0, max_val], 'r--', label='Equal asks/bids')\n",
        "    axes[0, 1].set_xlabel('Bid Count')\n",
        "    axes[0, 1].set_ylabel('Ask Count')\n",
        "    axes[0, 1].set_title('Ask vs Bid Counts')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Imbalance ratio vs Spread (with trend line)\n",
        "    axes[1, 0].scatter(df_imbalance['imbalance_ratio'], df_imbalance['spread_pct'], alpha=0.6)\n",
        "    # Add trend line\n",
        "    z = np.polyfit(df_imbalance['imbalance_ratio'], df_imbalance['spread_pct'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    x_trend = np.linspace(df_imbalance['imbalance_ratio'].min(), \n",
        "                         df_imbalance['imbalance_ratio'].max(), 100)\n",
        "    axes[1, 0].plot(x_trend, p(x_trend), \"r--\", alpha=0.8, label=f'Trend: y={z[0]:.2f}x+{z[1]:.2f}')\n",
        "    axes[1, 0].set_xlabel('Ask/Bid Ratio')\n",
        "    axes[1, 0].set_ylabel('Spread %')\n",
        "    axes[1, 0].set_title('Imbalance Ratio vs Spread (with trend)')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Box plot: spread by imbalance category\n",
        "    df_imbalance['imbalance_category'] = df_imbalance['imbalance_ratio'].apply(\n",
        "        lambda x: 'Ask-heavy (>2:1)' if x > 2 else ('Balanced (0.5-2)' if x > 0.5 else 'Bid-heavy (<0.5:1)')\n",
        "    )\n",
        "    df_imbalance.boxplot(column='spread_pct', by='imbalance_category', ax=axes[1, 1])\n",
        "    axes[1, 1].set_xlabel('Imbalance Category')\n",
        "    axes[1, 1].set_ylabel('Spread %')\n",
        "    axes[1, 1].set_title('Spread by Imbalance Category')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Statistical test\n",
        "    ask_heavy = df_imbalance[df_imbalance['imbalance_ratio'] > 2]['spread_pct']\n",
        "    balanced = df_imbalance[(df_imbalance['imbalance_ratio'] >= 0.5) & \n",
        "                           (df_imbalance['imbalance_ratio'] <= 2)]['spread_pct']\n",
        "    \n",
        "    if len(ask_heavy) > 0 and len(balanced) > 0:\n",
        "        print(f\"\\nAsk-heavy items (>2:1): {len(ask_heavy)} items, mean spread: {ask_heavy.mean():.2f}%\")\n",
        "        print(f\"Balanced items (0.5-2:1): {len(balanced)} items, mean spread: {balanced.mean():.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter: Volatility vs Expected PnL\n",
        "if len(df_risk) > 0:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(df_risk['volatility'], df_risk['expected_pnl'], alpha=0.6)\n",
        "    plt.xlabel('Volatility (daily)')\n",
        "    plt.ylabel('Expected PnL after hold')\n",
        "    plt.title('Volatility vs Expected PnL (3-day hold)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top candidates table\n",
        "if len(df_risk) > 0:\n",
        "    df_top = df_risk.nlargest(10, 'expected_pnl')\n",
        "    print(\"Top 10 Candidates by Expected PnL:\")\n",
        "    print(df_top[['market_hash_name', 'pnl_now', 'expected_pnl', 'prob_positive', 'var_95']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Buff Ask-Only Pressure Analysis\n",
        "\n",
        "Testing theory: Steam's lack of direct cashouts vs Buff's cashout capability creates ask-only pressure on Buff (sellers want to exit, fewer buyers).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze Buff order book imbalance\n",
        "# Theory: More asks than bids = sellers want to exit (cashout pressure)\n",
        "# Compare ask/bid depth and order counts\n",
        "\n",
        "buff_imbalance_data = []\n",
        "\n",
        "for _, row in df_clean.iterrows():\n",
        "    item_id = row['item_id']\n",
        "    \n",
        "    # Get latest Buff snapshot\n",
        "    conn = db_client.get_connection()\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT best_ask, best_bid, sell_order_count, buy_order_count\n",
        "        FROM buff_snapshots\n",
        "        WHERE item_id = ?\n",
        "        ORDER BY timestamp DESC\n",
        "        LIMIT 1\n",
        "    \"\"\", (item_id,))\n",
        "    \n",
        "    buff_row = cursor.fetchone()\n",
        "    conn.close()\n",
        "    \n",
        "    if buff_row and buff_row['sell_order_count'] and buff_row['buy_order_count']:\n",
        "        ask_count = buff_row['sell_order_count'] or 0\n",
        "        bid_count = buff_row['buy_order_count'] or 0\n",
        "        \n",
        "        if ask_count > 0 or bid_count > 0:\n",
        "            imbalance_ratio = ask_count / (bid_count + 1)  # +1 to avoid div by zero\n",
        "            buff_imbalance_data.append({\n",
        "                'item_id': item_id,\n",
        "                'market_hash_name': row['market_hash_name'],\n",
        "                'ask_count': ask_count,\n",
        "                'bid_count': bid_count,\n",
        "                'imbalance_ratio': imbalance_ratio,\n",
        "                'spread_pct': row.get('spread_pct', 0)\n",
        "            })\n",
        "\n",
        "df_imbalance = pd.DataFrame(buff_imbalance_data)\n",
        "\n",
        "if len(df_imbalance) > 0:\n",
        "    print(\"Buff Order Book Imbalance Analysis:\")\n",
        "    print(f\"Average ask/bid ratio: {df_imbalance['imbalance_ratio'].mean():.2f}\")\n",
        "    print(f\"Items with more asks than bids: {(df_imbalance['imbalance_ratio'] > 1).sum()} / {len(df_imbalance)}\")\n",
        "    print(f\"\\nTop 10 by imbalance ratio (ask-heavy):\")\n",
        "    print(df_imbalance.nlargest(10, 'imbalance_ratio')[['market_hash_name', 'ask_count', 'bid_count', 'imbalance_ratio', 'spread_pct']])\n",
        "    \n",
        "    # Scatter: imbalance ratio vs spread\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(df_imbalance['imbalance_ratio'], df_imbalance['spread_pct'], alpha=0.6)\n",
        "    plt.xlabel('Ask/Bid Ratio (higher = more asks)')\n",
        "    plt.ylabel('Spread %')\n",
        "    plt.title('Buff Order Book Imbalance vs Spread')\n",
        "    plt.axvline(x=1, color='r', linestyle='--', label='Balanced (1:1)')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No Buff order book data available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Summary Statistics:\")\n",
        "print(f\"Total items analyzed: {len(df_clean)}\")\n",
        "print(f\"Items with positive PnL: {len(df_positive)}\")\n",
        "print(f\"Average PnL (positive only): {df_positive['pnl_now'].mean():.2f}\")\n",
        "print(f\"Median PnL (positive only): {df_positive['pnl_now'].median():.2f}\")\n",
        "print(f\"Max PnL: {df_positive['pnl_now'].max():.2f}\")\n",
        "\n",
        "if len(df_risk) > 0:\n",
        "    print(f\"\\nRisk Analysis (top candidates):\")\n",
        "    print(f\"Average probability of positive PnL: {df_risk['prob_positive'].mean():.2f}\")\n",
        "    print(f\"Average expected PnL: {df_risk['expected_pnl'].mean():.2f}\")\n",
        "    print(f\"Average 95% VaR: {df_risk['var_95'].mean():.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
